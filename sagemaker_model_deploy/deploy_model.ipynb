{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install -qU pip sagemaker transformers"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "805acd03a88c8689",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%writefile inference.py\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def model_fn(model_dir):\n",
    "\tdevice = 0 if torch.cuda.is_available() else -1\n",
    "\tmodel = AutoModelForCausalLM.from_pretrained(model_dir).to(device)\n",
    "\ttokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\treturn model, tokenizer\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "\tif request_content_type == 'application/json':\n",
    "\t\trequest = json.loads(request_body)\n",
    "\t\traw_text = request['text']\n",
    "\t\treturn raw_text\n",
    "\telse:\n",
    "\t\traise ValueError(\"Content type {} not supported\".format(request_content_type))\n",
    "\t\n",
    "def predict_fn(input_data, model):\n",
    "\t# Construct formatted input for the model\n",
    "\tmessages = [\n",
    "\t\t{\n",
    "\t\t\"role\": \"system\",\n",
    "\t\t\"content\": \"You are a helpful, respectful, expert mental health assistant. Respond to the User with empathy and respect.\"\n",
    "\t\t}\n",
    "\t]\n",
    "\tfor i, message in enumerate(input_data):\n",
    "\t\tif i % 2 != 0:\n",
    "\t\t\tmessages.append({\"role\": \"assistant\", \"content\": message})\n",
    "\t\telse:\n",
    "\t\t\tmessages.append({\"role\": \"user\", \"content\": message})\n",
    "\ttext = model[1].apply_chat_template(messages, tokenize=False)\n",
    "\tinputs = model[1](text, return_tensors=\"pt\", padding=True, truncation=True, max_length=1024, add_special_tokens=False)\n",
    "\tinput_ids = inputs.input_ids.to(model[0].device)\n",
    "\toutputs = model[0].generate(input_ids, max_new_tokens=768)\n",
    "\treturn model[1].decode(outputs[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "\tif content_type == 'application/json':\n",
    "\t\treturn json.dumps({\"generated_text\": prediction})\n",
    "\telse:\n",
    "\t\traise ValueError(\"Content type {} not supported\".format(content_type))"
   ],
   "id": "ac58abbbfdb2016f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'jeffreykthomas/llama-mental-health',\n",
    "\t'SM_NUM_GPUS': json.dumps(1)\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.4.2\"),\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")\n",
    "\n",
    "endpoint_config_name = 'llama-mental-health-endpoint'\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g4dn.xlarge\",\n",
    "\tcontainer_startup_health_check_timeout=300,\n",
    "    endpoint_name=endpoint_config_name\n",
    "  )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ae6a1eb1fc040fc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# send test request\n",
    "predictor.predict({\n",
    "\t\"inputs\": \"My name is Julien and I like to\",\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ecde28414e75524",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# delete endpoint\n",
    "predictor.delete_endpoint()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87266ff5a362a20",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "351cd4ab45996af0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
